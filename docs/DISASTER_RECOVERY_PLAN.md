# ğŸ›¡ï¸ QLP Disaster Recovery & Business Continuity Plan

## ğŸ“‹ Executive Summary

This document outlines the disaster recovery (DR) and business continuity strategy for QuantumLayer (QLP) running on Microsoft Azure, ensuring minimal downtime and data loss in case of service disruptions.

### **Recovery Objectives**
- **RTO (Recovery Time Objective)**: 2 hours for critical services
- **RPO (Recovery Point Objective)**: 15 minutes maximum data loss
- **Availability Target**: 99.9% uptime (8.76 hours downtime/year)
- **Data Retention**: 30 days backup retention, 7 years compliance data

---

## ğŸ¯ Disaster Recovery Strategy

### **Multi-Layer Recovery Approach**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DR Architecture                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Primary Region (UK South)     â”‚  Secondary Region (UK West)â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Production Environment â”‚   â”‚  â”‚    DR Environment       â”‚â”‚
â”‚  â”‚  â€¢ Container Instances  â”‚   â”‚  â”‚  â€¢ Standby Containers   â”‚â”‚
â”‚  â”‚  â€¢ PostgreSQL Primary   â”‚â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â€¢ PostgreSQL Replica   â”‚â”‚
â”‚  â”‚  â€¢ Storage Account      â”‚   â”‚  â”‚  â€¢ Storage Replication  â”‚â”‚
â”‚  â”‚  â€¢ Application Insights â”‚   â”‚  â”‚  â€¢ Monitoring (Standby) â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                 â”‚                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              Azure Front Door                           â”‚ â”‚
â”‚  â”‚         (Automatic Failover)                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Recovery Tiers**

#### **Tier 1: Critical Services (RTO: 30 minutes)**
- **Intent Processing API**: Core QLP functionality
- **Database Services**: PostgreSQL with vector data
- **Authentication**: User access and security
- **Container Registry**: Essential for deployments

#### **Tier 2: Important Services (RTO: 2 hours)**
- **WebSocket Real-time Updates**: UI communication
- **Monitoring & Logging**: Application Insights
- **Static Assets**: Documentation and UI resources
- **Backup Services**: Secondary recovery systems

#### **Tier 3: Non-Critical Services (RTO: 4 hours)**
- **Analytics & Reporting**: Historical data analysis
- **Development Tools**: CI/CD pipeline restoration
- **Documentation Sites**: External documentation
- **Archive Storage**: Long-term data retention

---

## ğŸ’¾ Backup Strategy

### **Database Backup (PostgreSQL)**

#### **Automated Backup Configuration**
```hcl
# Terraform configuration for backup
resource "azurerm_postgresql_flexible_server" "main" {
  # ... other configuration ...
  
  backup_retention_days        = 30
  geo_redundant_backup_enabled = true
  point_in_time_restore_enabled = true
  
  # High availability for production
  high_availability {
    mode                      = "ZoneRedundant"
    standby_availability_zone = "2"
  }
}

# Long-term backup storage
resource "azurerm_storage_account" "backup" {
  name                     = "qlpbackupstorage"
  resource_group_name      = azurerm_resource_group.main.name
  location                = azurerm_resource_group.main.location
  account_tier            = "Standard"
  account_replication_type = "GRS"
  
  blob_properties {
    versioning_enabled = true
    delete_retention_policy {
      days = 365
    }
  }
}
```

#### **Backup Schedule**
```yaml
Automated Backups:
  - Continuous: Transaction log backups every 15 minutes
  - Full Backup: Daily at 2:00 AM UTC
  - Differential: Every 6 hours
  - Long-term: Weekly backup retained for 7 years

Manual Backups:
  - Pre-deployment: Before major releases
  - Pre-maintenance: Before infrastructure changes
  - Ad-hoc: On-demand for testing or migrations
```

#### **Backup Verification Script**
```bash
#!/bin/bash
# backup-verification.sh

# Check latest backup status
check_backup_status() {
    echo "ğŸ” Checking PostgreSQL backup status..."
    
    az postgres flexible-server backup list \
        --resource-group $RESOURCE_GROUP \
        --server-name $DB_SERVER_NAME \
        --query '[0].{Name:name, Status:status, StartTime:startTime, EndTime:endTime}' \
        --output table
}

# Verify backup integrity
verify_backup_integrity() {
    echo "âœ… Verifying backup integrity..."
    
    # Test restore to temporary instance
    TEMP_SERVER="${DB_SERVER_NAME}-test-$(date +%s)"
    
    az postgres flexible-server restore \
        --source-server $DB_SERVER_NAME \
        --resource-group $RESOURCE_GROUP \
        --name $TEMP_SERVER \
        --restore-time "$(date -u -d '1 hour ago' +%Y-%m-%dT%H:%M:%SZ)" \
        --no-wait
    
    # Cleanup test server after verification
    sleep 300
    az postgres flexible-server delete \
        --resource-group $RESOURCE_GROUP \
        --name $TEMP_SERVER \
        --yes
}

check_backup_status
verify_backup_integrity
```

### **Application Data Backup**

#### **Container Persistent Storage**
```yaml
Storage Backup Strategy:
  - QuantumCapsules: Real-time replication to secondary region
  - User Data: Hourly snapshots with 30-day retention
  - Configuration: Version-controlled in Git with backup
  - Logs: Streaming to Log Analytics with 90-day retention

Backup Components:
  - Application Configuration
  - User-generated QuantumCapsules
  - System logs and audit trails
  - Container images and versions
```

#### **Backup Monitoring**
```go
// Backup monitoring service
package backup

import (
    "context"
    "time"
    "github.com/Azure/azure-sdk-for-go/sdk/storage/azblob"
)

type BackupMonitor struct {
    blobClient   *azblob.Client
    alertService AlertService
}

func (bm *BackupMonitor) MonitorBackups() {
    ticker := time.NewTicker(1 * time.Hour)
    defer ticker.Stop()

    for {
        select {
        case <-ticker.C:
            if err := bm.verifyLatestBackups(); err != nil {
                bm.alertService.SendAlert("Backup verification failed", err)
            }
        }
    }
}

func (bm *BackupMonitor) verifyLatestBackups() error {
    // Check database backup timestamp
    dbBackupAge, err := bm.getLatestDBBackupAge()
    if err != nil {
        return err
    }
    
    if dbBackupAge > 4*time.Hour {
        return fmt.Errorf("database backup is %v old", dbBackupAge)
    }
    
    // Check storage backup replication
    if err := bm.verifyStorageReplication(); err != nil {
        return fmt.Errorf("storage replication failed: %w", err)
    }
    
    return nil
}
```

---

## ğŸ”„ Disaster Recovery Procedures

### **Scenario 1: Primary Region Outage**

#### **Detection & Alert (0-5 minutes)**
```bash
# Automated monitoring alerts
Monitor triggers:
- Health check failures (3 consecutive failures)
- Database connection timeouts (>30 seconds)
- Container instance unavailability
- Network connectivity issues

Notification channels:
- PagerDuty incident creation
- Slack emergency channel
- SMS to on-call engineer
- Email to leadership team
```

#### **Assessment & Decision (5-15 minutes)**
```yaml
Assessment Checklist:
- [ ] Verify outage scope (regional vs service-specific)
- [ ] Check Azure Service Health status
- [ ] Confirm backup data integrity
- [ ] Estimate recovery time for primary vs failover
- [ ] Notify stakeholders of incident

Decision Matrix:
- <30 min expected: Wait for primary recovery
- 30-60 min expected: Prepare failover, continue monitoring
- >60 min expected: Execute immediate failover
```

#### **Failover Execution (15-45 minutes)**
```bash
#!/bin/bash
# disaster-failover.sh

set -e
echo "ğŸš¨ EXECUTING DISASTER RECOVERY FAILOVER"

# 1. Switch DNS to secondary region
echo "ğŸ“¡ Updating DNS to secondary region..."
az network front-door routing-rule update \
    --front-door-name $FRONTDOOR_NAME \
    --resource-group $RESOURCE_GROUP \
    --name default-routing-rule \
    --backend-pool secondary-backend-pool

# 2. Promote database replica
echo "ğŸ—„ï¸ Promoting database replica..."
az postgres flexible-server replica promote \
    --resource-group $SECONDARY_RESOURCE_GROUP \
    --name $SECONDARY_DB_NAME

# 3. Start secondary container instances
echo "ğŸ³ Starting secondary containers..."
az container restart \
    --resource-group $SECONDARY_RESOURCE_GROUP \
    --name $SECONDARY_CONTAINER_GROUP

# 4. Update configuration
echo "âš™ï¸ Updating application configuration..."
az keyvault secret set \
    --vault-name $SECONDARY_KEYVAULT \
    --name database-url \
    --value "postgres://$SECONDARY_DB_CONNECTION"

# 5. Verify services
echo "âœ… Verifying failover services..."
timeout 300 bash -c 'until curl -f $SECONDARY_ENDPOINT/health; do sleep 10; done'

echo "ğŸ‰ Failover completed successfully!"
echo "ğŸ“Š Services running on secondary region: $SECONDARY_REGION"
```

### **Scenario 2: Database Corruption**

#### **Point-in-Time Recovery**
```bash
#!/bin/bash
# database-recovery.sh

# Identify corruption time
CORRUPTION_TIME=$(date -u -d "$1" +%Y-%m-%dT%H:%M:%SZ)
echo "ğŸ•’ Recovering to point: $CORRUPTION_TIME"

# Create recovery instance
RECOVERY_SERVER="${DB_SERVER_NAME}-recovery-$(date +%s)"

az postgres flexible-server restore \
    --source-server $DB_SERVER_NAME \
    --resource-group $RESOURCE_GROUP \
    --name $RECOVERY_SERVER \
    --restore-time $CORRUPTION_TIME

# Verify data integrity
echo "ğŸ” Verifying recovered data..."
psql -h ${RECOVERY_SERVER}.postgres.database.azure.com \
     -U $DB_ADMIN \
     -d qlp_db \
     -c "SELECT COUNT(*) FROM intents;"

# Switch application to recovery database
echo "ğŸ”„ Switching application to recovery database..."
# Update connection strings and restart services
```

### **Scenario 3: Container Service Failure**

#### **Container Recovery Process**
```yaml
Container Failure Response:
1. Automatic Restart (0-2 minutes):
   - Azure Container Instances automatic restart
   - Health check validation
   - Load balancer adjustment

2. Image Rollback (2-10 minutes):
   - Identify last known good image
   - Deploy previous container version
   - Verify application functionality

3. Full Redeployment (10-30 minutes):
   - Redeploy from source code
   - Fresh container instance creation
   - Complete environment rebuild
```

---

## ğŸ“‹ Deployment Playbook

### **Pre-Deployment Checklist**

#### **Planning Phase**
```yaml
Deployment Planning:
- [ ] Change request approved and documented
- [ ] Deployment window scheduled (low-traffic hours)
- [ ] Rollback plan prepared and tested
- [ ] Database migration scripts reviewed
- [ ] Team notification sent (24 hours advance)
- [ ] Monitoring alerts temporarily adjusted
- [ ] Customer communication prepared (if needed)
```

#### **Pre-Flight Verification**
```bash
#!/bin/bash
# pre-deployment-check.sh

echo "ğŸ” Pre-deployment verification starting..."

# 1. Verify backup status
echo "ğŸ’¾ Checking backup status..."
LATEST_BACKUP=$(az postgres flexible-server backup list \
    --resource-group $RESOURCE_GROUP \
    --server-name $DB_SERVER_NAME \
    --query '[0].startTime' -o tsv)

BACKUP_AGE=$(( ($(date +%s) - $(date -d "$LATEST_BACKUP" +%s)) / 3600 ))
if [ $BACKUP_AGE -gt 6 ]; then
    echo "âŒ Latest backup is $BACKUP_AGE hours old. Triggering fresh backup..."
    # Trigger manual backup
    exit 1
fi

# 2. Verify system health
echo "ğŸ¥ Checking system health..."
HEALTH_STATUS=$(curl -s -o /dev/null -w "%{http_code}" $PRODUCTION_URL/health)
if [ $HEALTH_STATUS -ne 200 ]; then
    echo "âŒ Health check failed: $HEALTH_STATUS"
    exit 1
fi

# 3. Check resource utilization
echo "ğŸ“Š Checking resource utilization..."
CPU_USAGE=$(az monitor metrics list \
    --resource $CONTAINER_RESOURCE_ID \
    --metric "CpuUsage" \
    --query 'value[0].timeseries[0].data[-1].average')

if (( $(echo "$CPU_USAGE > 80" | bc -l) )); then
    echo "âš ï¸ High CPU usage: ${CPU_USAGE}%"
    echo "Consider deploying during lower traffic period"
fi

echo "âœ… Pre-deployment checks passed!"
```

### **Deployment Execution**

#### **Blue-Green Deployment Process**
```bash
#!/bin/bash
# blue-green-deploy.sh

set -e

CURRENT_SLOT="blue"
NEW_SLOT="green"
IMAGE_TAG=${1:-latest}

echo "ğŸš€ Starting blue-green deployment..."
echo "ğŸ“¦ Deploying image: $IMAGE_TAG"
echo "ğŸ¯ Target slot: $NEW_SLOT"

# 1. Deploy to green slot
echo "ğŸŸ¢ Deploying to $NEW_SLOT slot..."
az container create \
    --resource-group $RESOURCE_GROUP \
    --name "qlp-${NEW_SLOT}" \
    --image "${ACR_NAME}.azurecr.io/qlp:${IMAGE_TAG}" \
    --cpu 2 \
    --memory 8 \
    --restart-policy Always \
    --environment-variables \
        QLP_MODE=production \
        DATABASE_URL="@Microsoft.KeyVault(SecretUri=${KV_DB_SECRET})" \
    --ports 8080

# 2. Wait for green slot to be healthy
echo "â³ Waiting for $NEW_SLOT slot to become healthy..."
timeout 300 bash -c "
    while true; do
        STATUS=\$(az container show \
            --resource-group $RESOURCE_GROUP \
            --name qlp-${NEW_SLOT} \
            --query 'containers[0].instanceView.currentState.state' -o tsv)
        
        if [ \"\$STATUS\" = \"Running\" ]; then
            echo \"âœ… Container is running, checking health endpoint...\"
            if curl -f http://\$(az container show \
                --resource-group $RESOURCE_GROUP \
                --name qlp-${NEW_SLOT} \
                --query 'ipAddress.ip' -o tsv):8080/health; then
                echo \"âœ… Health check passed!\"
                break
            fi
        fi
        
        echo \"â³ Container status: \$STATUS, waiting...\"
        sleep 10
    done
"

# 3. Run smoke tests on green slot
echo "ğŸ§ª Running smoke tests on $NEW_SLOT slot..."
GREEN_IP=$(az container show \
    --resource-group $RESOURCE_GROUP \
    --name "qlp-${NEW_SLOT}" \
    --query 'ipAddress.ip' -o tsv)

# Test intent processing
curl -X POST "http://${GREEN_IP}:8080/api/v1/intents" \
    -H "Content-Type: application/json" \
    -d '{"user_input": "Create a simple hello world API"}' \
    | jq '.status' | grep -q "success"

echo "âœ… Smoke tests passed!"

# 4. Switch traffic to green slot
echo "ğŸ”„ Switching traffic to $NEW_SLOT slot..."
az network front-door routing-rule update \
    --front-door-name $FRONTDOOR_NAME \
    --resource-group $RESOURCE_GROUP \
    --name default-routing-rule \
    --backend-pool "qlp-${NEW_SLOT}-pool"

# 5. Monitor for 5 minutes
echo "ğŸ“Š Monitoring $NEW_SLOT slot for 5 minutes..."
for i in {1..30}; do
    HEALTH_STATUS=$(curl -s -o /dev/null -w "%{http_code}" $PRODUCTION_URL/health)
    if [ $HEALTH_STATUS -ne 200 ]; then
        echo "âŒ Health check failed after traffic switch!"
        echo "ğŸ”„ Rolling back to $CURRENT_SLOT slot..."
        # Rollback logic here
        exit 1
    fi
    echo "âœ… Health check $i/30 passed"
    sleep 10
done

# 6. Cleanup old slot
echo "ğŸ§¹ Cleaning up $CURRENT_SLOT slot..."
az container delete \
    --resource-group $RESOURCE_GROUP \
    --name "qlp-${CURRENT_SLOT}" \
    --yes

echo "ğŸ‰ Deployment completed successfully!"
echo "ğŸ“Š New version deployed: $IMAGE_TAG"
```

#### **Database Migration Deployment**
```bash
#!/bin/bash
# database-migration-deploy.sh

set -e

MIGRATION_VERSION=${1:-latest}
echo "ğŸ—„ï¸ Starting database migration: $MIGRATION_VERSION"

# 1. Create database backup before migration
echo "ğŸ’¾ Creating pre-migration backup..."
BACKUP_NAME="pre-migration-$(date +%Y%m%d-%H%M%S)"
# Azure PostgreSQL automatic backup is sufficient
echo "âœ… Backup created: $BACKUP_NAME"

# 2. Put application in maintenance mode
echo "ğŸš§ Enabling maintenance mode..."
az container update \
    --resource-group $RESOURCE_GROUP \
    --name $CONTAINER_GROUP_NAME \
    --set containers[0].environmentVariables[0].name="MAINTENANCE_MODE" \
    --set containers[0].environmentVariables[0].value="true"

# 3. Wait for active connections to drain
echo "â³ Waiting for connections to drain..."
sleep 30

# 4. Run database migrations
echo "ğŸ”„ Running database migrations..."
docker run --rm \
    -e DATABASE_URL="$DATABASE_URL" \
    "${ACR_NAME}.azurecr.io/qlp-migrations:${MIGRATION_VERSION}" \
    migrate up

# 5. Verify migration success
echo "âœ… Verifying migration..."
MIGRATION_STATUS=$(docker run --rm \
    -e DATABASE_URL="$DATABASE_URL" \
    "${ACR_NAME}.azurecr.io/qlp-migrations:${MIGRATION_VERSION}" \
    migrate version)

echo "ğŸ“Š Current migration version: $MIGRATION_STATUS"

# 6. Disable maintenance mode
echo "ğŸŸ¢ Disabling maintenance mode..."
az container update \
    --resource-group $RESOURCE_GROUP \
    --name $CONTAINER_GROUP_NAME \
    --set containers[0].environmentVariables[0].name="MAINTENANCE_MODE" \
    --set containers[0].environmentVariables[0].value="false"

echo "ğŸ‰ Database migration completed successfully!"
```

### **Post-Deployment Verification**

#### **Automated Testing Suite**
```bash
#!/bin/bash
# post-deployment-tests.sh

echo "ğŸ§ª Running post-deployment test suite..."

# 1. API Health Tests
echo "ğŸ¥ Testing API health endpoints..."
curl -f $PRODUCTION_URL/health || exit 1
curl -f $PRODUCTION_URL/api/v1/status || exit 1

# 2. Database Connectivity
echo "ğŸ—„ï¸ Testing database connectivity..."
curl -f $PRODUCTION_URL/api/v1/health/database || exit 1

# 3. Vector Search Functionality
echo "ğŸ” Testing vector search..."
SEARCH_RESPONSE=$(curl -s -X POST "$PRODUCTION_URL/api/v1/search" \
    -H "Content-Type: application/json" \
    -d '{"query": "create API"}')

echo $SEARCH_RESPONSE | jq -e '.results | length > 0' || exit 1

# 4. Intent Processing
echo "ğŸ¯ Testing intent processing..."
INTENT_RESPONSE=$(curl -s -X POST "$PRODUCTION_URL/api/v1/intents" \
    -H "Content-Type: application/json" \
    -d '{"user_input": "Build a simple REST API"}')

INTENT_ID=$(echo $INTENT_RESPONSE | jq -r '.intent_id')
echo "âœ… Intent created: $INTENT_ID"

# 5. Performance Tests
echo "ğŸ“Š Running performance tests..."
ab -n 100 -c 10 "$PRODUCTION_URL/health" > /tmp/perf_results.txt
AVG_RESPONSE=$(grep "Time per request" /tmp/perf_results.txt | head -1 | awk '{print $4}')

if (( $(echo "$AVG_RESPONSE > 500" | bc -l) )); then
    echo "âš ï¸ Performance degradation detected: ${AVG_RESPONSE}ms average"
    exit 1
fi

echo "âœ… All post-deployment tests passed!"
echo "ğŸ“Š Average response time: ${AVG_RESPONSE}ms"
```

### **Rollback Procedures**

#### **Automatic Rollback Triggers**
```yaml
Rollback Conditions:
- Health check failures (>50% in 5 minutes)
- Error rate increase (>5% above baseline)
- Response time degradation (>2x baseline)
- Database connection failures
- Critical functionality broken

Rollback Process:
1. Immediate: Switch traffic back to previous version
2. Fast: Redeploy previous container image
3. Complete: Full infrastructure rollback including database
```

#### **Emergency Rollback Script**
```bash
#!/bin/bash
# emergency-rollback.sh

ROLLBACK_REASON=${1:-"Emergency rollback"}
PREVIOUS_VERSION=${2:-"previous"}

echo "ğŸš¨ EMERGENCY ROLLBACK INITIATED"
echo "ğŸ“ Reason: $ROLLBACK_REASON"
echo "ğŸ”™ Rolling back to: $PREVIOUS_VERSION"

# 1. Switch traffic immediately
echo "âš¡ Switching traffic to previous version..."
az network front-door routing-rule update \
    --front-door-name $FRONTDOOR_NAME \
    --resource-group $RESOURCE_GROUP \
    --name default-routing-rule \
    --backend-pool "qlp-blue-pool"  # Previous stable version

# 2. Deploy previous container version
echo "ğŸ³ Deploying previous container version..."
az container update \
    --resource-group $RESOURCE_GROUP \
    --name $CONTAINER_GROUP_NAME \
    --image "${ACR_NAME}.azurecr.io/qlp:${PREVIOUS_VERSION}"

# 3. Verify rollback success
echo "âœ… Verifying rollback..."
timeout 120 bash -c 'until curl -f $PRODUCTION_URL/health; do sleep 5; done'

# 4. Send notifications
echo "ğŸ“§ Sending rollback notifications..."
curl -X POST $SLACK_WEBHOOK \
    -H 'Content-type: application/json' \
    -d "{\"text\":\"ğŸš¨ QLP Emergency Rollback Completed\nğŸ“ Reason: $ROLLBACK_REASON\nğŸ”™ Version: $PREVIOUS_VERSION\"}"

echo "âœ… Emergency rollback completed!"
```

---

## ğŸ“Š Recovery Testing

### **Quarterly DR Tests**

#### **Test Schedule**
```yaml
DR Test Calendar:
- Q1: Database failure simulation
- Q2: Regional outage simulation  
- Q3: Complete disaster recovery test
- Q4: Security incident response

Monthly Tests:
- Backup restoration verification
- Failover procedure validation
- Performance baseline testing
- Security scan and remediation

Weekly Tests:
- Health check validation
- Monitoring alert verification
- Backup integrity checks
- Documentation review
```

#### **DR Test Automation**
```bash
#!/bin/bash
# dr-test-automation.sh

TEST_TYPE=${1:-"basic"}
echo "ğŸ§ª Starting DR test: $TEST_TYPE"

case $TEST_TYPE in
    "database")
        echo "ğŸ—„ï¸ Testing database recovery..."
        # Simulate database failure and recovery
        ;;
    "region")
        echo "ğŸŒ Testing regional failover..."
        # Test secondary region activation
        ;;
    "complete")
        echo "ğŸ”¥ Testing complete disaster recovery..."
        # Full DR scenario test
        ;;
    *)
        echo "âŒ Unknown test type: $TEST_TYPE"
        exit 1
        ;;
esac
```

---

## ğŸ“ Incident Response

### **On-Call Rotation**
```yaml
Escalation Matrix:
Level 1: On-call Engineer (0-15 minutes)
Level 2: Senior Engineer (15-30 minutes)  
Level 3: Technical Lead (30-60 minutes)
Level 4: Engineering Manager (60+ minutes)

Contact Methods:
- PagerDuty primary alerting
- Slack emergency channel
- Phone/SMS backup
- Email notifications

Response SLAs:
- Critical (P0): 15 minutes
- High (P1): 30 minutes
- Medium (P2): 2 hours
- Low (P3): Next business day
```

### **Incident Communication**
```yaml
Communication Channels:
- Status Page: Real-time customer updates
- Slack: Internal team coordination
- Email: Stakeholder notifications
- Social Media: Public incident updates (if needed)

Update Frequency:
- During Incident: Every 30 minutes
- Post-Resolution: Within 1 hour
- Post-Mortem: Within 48 hours
```

---

## ğŸ¯ Key Contacts & Resources

### **Emergency Contacts**
```yaml
Primary On-Call: [PHONE] [EMAIL]
Secondary On-Call: [PHONE] [EMAIL]
Engineering Manager: [PHONE] [EMAIL]
CTO: [PHONE] [EMAIL]

External Vendors:
- Azure Support: [SUPPORT_CASE_URL]
- DNS Provider: [SUPPORT_CONTACT]
- Third-party Services: [CONTACT_LIST]
```

### **Critical Resources**
```yaml
Documentation:
- Runbooks: /docs/runbooks/
- Architecture: /docs/architecture/
- Procedures: /docs/procedures/

Tools:
- Azure Portal: portal.azure.com
- Monitoring: [APPLICATION_INSIGHTS_URL]
- Logs: [LOG_ANALYTICS_URL]
- Status: [STATUS_PAGE_URL]

Access:
- Azure Subscription: [SUBSCRIPTION_ID]
- Emergency Access: [BREAK_GLASS_PROCEDURE]
- Service Accounts: [SERVICE_ACCOUNT_LIST]
```

---

*This disaster recovery plan ensures QLP can maintain business continuity and quickly recover from various failure scenarios while minimizing data loss and service disruption.*