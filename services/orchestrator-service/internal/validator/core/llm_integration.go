package core

import (
	"context"
	"encoding/json"
	"fmt"
	"strings"

	"QLP/internal/llm"
)

// DefaultLLMIntegration implements the LLMIntegration interface
type DefaultLLMIntegration struct {
	llmClient llm.Client
	parsers   map[ResponseType]ResponseParser
}

// ResponseParser defines interface for parsing different response types
type ResponseParser interface {
	Parse(response string, target interface{}) error
	Validate(response string) error
}

// NewDefaultLLMIntegration creates a new LLM integration layer
func NewDefaultLLMIntegration(llmClient llm.Client) *DefaultLLMIntegration {
	integration := &DefaultLLMIntegration{
		llmClient: llmClient,
		parsers: map[ResponseType]ResponseParser{
			ResponseTypeJSON:       &JSONResponseParser{},
			ResponseTypeStructured: &StructuredResponseParser{},
			ResponseTypeText:       &TextResponseParser{},
		},
	}

	return integration
}

// GeneratePrompt creates a prompt based on input and type, now dynamically generated by an LLM.
func (dli *DefaultLLMIntegration) GeneratePrompt(input *ValidationInput, promptType PromptType) (string, error) {
	// Use a background context for the meta-prompt generation.
	// A production implementation should thread a real context through.
	ctx := context.Background()

	return dli.generatePromptViaLLM(ctx, input, promptType)
}

// generatePromptViaLLM uses the LLM to generate a prompt for another LLM.
func (dli *DefaultLLMIntegration) generatePromptViaLLM(ctx context.Context, input *ValidationInput, promptType PromptType) (string, error) {
	// 1. Construct the Meta-Prompt.
	// This prompt instructs the LLM on how to create a good prompt for the downstream task.
	var metaPromptBuilder strings.Builder

	metaPromptBuilder.WriteString("You are an expert in prompt engineering for large language models. Your task is to generate a complete and effective prompt for another AI assistant.")
	metaPromptBuilder.WriteString(fmt.Sprintf(" The assistant's goal is to perform a '%s' task on a software project.", promptType))
	metaPromptBuilder.WriteString(fmt.Sprintf(" The project is written in %s and may use the %s framework.", input.Language, input.Framework))

	metaPromptBuilder.WriteString(`
The generated prompt must be comprehensive and guide the assistant to produce a detailed, enterprise-grade response.
Crucially, the prompt you generate must instruct the target AI to:
1. Produce code that is 100% runnable, self-contained, and includes all necessary imports and dependencies.
2. Generate a 'README.md' file explaining how to build and run the code.
3. Generate a comprehensive suite of unit tests for the code it produces (e.g., 'main_test.go').
4. Structure its entire output as a single JSON object containing separate fields for each file. For example: {"main.go": "...", "main_test.go": "...", "README.md": "..."}.
5. Ensure the code adheres to the highest enterprise standards for security, maintainability, and performance.
`)

	metaPromptBuilder.WriteString("\n\nUse the following context to construct the prompt for the assistant:\n")
	metaPromptBuilder.WriteString(fmt.Sprintf("- Project Path: %s\n", input.ProjectPath))
	metaPromptBuilder.WriteString(fmt.Sprintf("- Project Type: %s\n", input.ProjectMetadata.ProjectType))
	if input.Requirements != nil && len(input.Requirements.ComplianceStandards) > 0 {
		metaPromptBuilder.WriteString(fmt.Sprintf("- User Requirements (Compliance): %s\n", strings.Join(input.Requirements.ComplianceStandards, ", ")))
	}

	metaPromptBuilder.WriteString("\nNow, generate the complete prompt for the AI assistant. The prompt you create should include placeholders for the actual code content, which will be injected later. For example, use a placeholder like '[[CODE_CONTENT]]'.")

	metaPrompt := metaPromptBuilder.String()

	// 2. Call the LLM with the meta-prompt.
	// The LLM's response will be the new, dynamic prompt template.
	promptTemplate, err := dli.llmClient.Complete(ctx, metaPrompt)
	if err != nil {
		return "", fmt.Errorf("failed to generate dynamic prompt template: %w", err)
	}

	// 3. Inject the actual code content into the dynamically generated prompt template.
	finalPrompt := strings.Replace(promptTemplate, "[[CODE_CONTENT]]", dli.formatContent(input.Content), -1)

	return finalPrompt, nil
}

// ParseResponse parses LLM response based on expected type
func (dli *DefaultLLMIntegration) ParseResponse(response string, expectedType ResponseType) (interface{}, error) {
	parser, exists := dli.parsers[expectedType]
	if !exists {
		return nil, fmt.Errorf("unsupported response type: %s", expectedType)
	}

	var result interface{}
	switch expectedType {
	case ResponseTypeJSON:
		result = &ValidationResult{}
	case ResponseTypeStructured:
		result = &StructuredAnalysis{}
	case ResponseTypeText:
		result = &TextAnalysis{}
	}

	if err := parser.Parse(response, result); err != nil {
		return nil, fmt.Errorf("failed to parse response: %w", err)
	}

	return result, nil
}

// GetPromptTemplate is now deprecated as we generate prompts dynamically.
// It will return an empty string.
func (dli *DefaultLLMIntegration) GetPromptTemplate(validatorType ValidatorType, promptType PromptType) string {
	return ""
}

// ValidateResponse checks if the response meets quality standards
func (dli *DefaultLLMIntegration) ValidateResponse(response interface{}) error {
	switch r := response.(type) {
	case *ValidationResult:
		return dli.validateValidationResult(r)
	case *StructuredAnalysis:
		return dli.validateStructuredAnalysis(r)
	case *TextAnalysis:
		return dli.validateTextAnalysis(r)
	default:
		return fmt.Errorf("unsupported response type for validation")
	}
}

// Helper methods are now focused on basic prompt fallbacks and content formatting

func (dli *DefaultLLMIntegration) formatContent(content map[string]string) string {
	var builder strings.Builder
	for filePath, fileContent := range content {
		builder.WriteString(fmt.Sprintf("\n--- File: %s ---\n", filePath))
		builder.WriteString(fileContent)
	}
	return builder.String()
}

func (dli *DefaultLLMIntegration) validateValidationResult(result *ValidationResult) error {
	if result.OverallScore < 0 || result.OverallScore > 100 {
		return fmt.Errorf("invalid overall score: %d (must be 0-100)", result.OverallScore)
	}

	if result.Confidence < 0.0 || result.Confidence > 1.0 {
		return fmt.Errorf("invalid confidence: %f (must be 0.0-1.0)", result.Confidence)
	}

	for component, score := range result.ComponentScores {
		if score < 0 || score > 100 {
			return fmt.Errorf("invalid component score for %s: %d (must be 0-100)", component, score)
		}
	}

	return nil
}

func (dli *DefaultLLMIntegration) validateStructuredAnalysis(analysis *StructuredAnalysis) error {
	if analysis.Language == "" {
		return fmt.Errorf("language is required in structured analysis")
	}

	if analysis.Confidence < 0.0 || analysis.Confidence > 1.0 {
		return fmt.Errorf("invalid confidence: %f (must be 0.0-1.0)", analysis.Confidence)
	}

	return nil
}

func (dli *DefaultLLMIntegration) validateTextAnalysis(analysis *TextAnalysis) error {
	if len(analysis.Content) < 10 {
		return fmt.Errorf("text analysis content too short: %d characters", len(analysis.Content))
	}

	return nil
}

// Response parser implementations

type JSONResponseParser struct{}

func (jrp *JSONResponseParser) Parse(response string, target interface{}) error {
	// Extract JSON from response (handle cases where LLM adds extra text)
	jsonStr := extractJSON(response)
	return json.Unmarshal([]byte(jsonStr), target)
}

func (jrp *JSONResponseParser) Validate(response string) error {
	jsonStr := extractJSON(response)
	var temp interface{}
	return json.Unmarshal([]byte(jsonStr), &temp)
}

type StructuredResponseParser struct{}

func (srp *StructuredResponseParser) Parse(response string, target interface{}) error {
	// Parse structured non-JSON response
	analysis := &StructuredAnalysis{
		Language:    extractField(response, "Language:"),
		Framework:   extractField(response, "Framework:"),
		Issues:      extractList(response, "Issues:"),
		Suggestions: extractList(response, "Suggestions:"),
		Confidence:  extractFloat(response, "Confidence:"),
	}

	if targetAnalysis, ok := target.(*StructuredAnalysis); ok {
		*targetAnalysis = *analysis
		return nil
	}

	return fmt.Errorf("target is not *StructuredAnalysis")
}

func (srp *StructuredResponseParser) Validate(response string) error {
	if len(response) < 50 {
		return fmt.Errorf("structured response too short")
	}
	return nil
}

type TextResponseParser struct{}

func (trp *TextResponseParser) Parse(response string, target interface{}) error {
	analysis := &TextAnalysis{
		Content:   response,
		WordCount: len(strings.Fields(response)),
	}

	if targetAnalysis, ok := target.(*TextAnalysis); ok {
		*targetAnalysis = *analysis
		return nil
	}

	return fmt.Errorf("target is not *TextAnalysis")
}

func (trp *TextResponseParser) Validate(response string) error {
	if len(response) < 10 {
		return fmt.Errorf("text response too short")
	}
	return nil
}

// Supporting types for different response formats

type StructuredAnalysis struct {
	Language    string   `json:"language"`
	Framework   string   `json:"framework"`
	Issues      []string `json:"issues"`
	Suggestions []string `json:"suggestions"`
	Confidence  float64  `json:"confidence"`
}

type TextAnalysis struct {
	Content   string `json:"content"`
	WordCount int    `json:"word_count"`
}

// Utility functions

func extractJSON(response string) string {
	// Find JSON block in response
	start := strings.Index(response, "{")
	if start == -1 {
		return "{}"
	}

	end := strings.LastIndex(response, "}")
	if end == -1 || end <= start {
		return "{}"
	}

	return response[start : end+1]
}

func extractField(response, fieldName string) string {
	lines := strings.Split(response, "\n")
	for _, line := range lines {
		if strings.Contains(line, fieldName) {
			parts := strings.SplitN(line, ":", 2)
			if len(parts) == 2 {
				return strings.TrimSpace(parts[1])
			}
		}
	}
	return ""
}

func extractList(response, fieldName string) []string {
	var items []string
	lines := strings.Split(response, "\n")
	inList := false

	for _, line := range lines {
		if strings.Contains(line, fieldName) {
			inList = true
			continue
		}

		if inList {
			line = strings.TrimSpace(line)
			if line == "" {
				break
			}
			if strings.HasPrefix(line, "-") || strings.HasPrefix(line, "*") {
				item := strings.TrimSpace(line[1:])
				items = append(items, item)
			}
		}
	}

	return items
}

func extractFloat(response, fieldName string) float64 {
	field := extractField(response, fieldName)
	if field == "" {
		return 0.0
	}

	// Simple float parsing
	var result float64
	fmt.Sscanf(field, "%f", &result)
	return result
}
